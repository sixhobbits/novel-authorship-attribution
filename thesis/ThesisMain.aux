\relax 
\citation{khonji2014slightly}
\citation{frery2014identification}
\citation{bagnall2015author}
\citation{bagnall2015author}
\citation{khonji2014slightly}
\citation{bagnall2015author}
\citation{khonji2014slightly}
\citation{mosteller2007inference}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:intro}{{1}{8}}
\citation{afroz2014doppelganger}
\citation{stamatatos2009survey}
\citation{stamatatos2009survey}
\citation{koppel2004authorship}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:back}{{2}{11}}
\citation{joachims1998text}
\citation{Kravalova:2009:CNE:1699705.1699748}
\citation{verhoeven2016twisty,busgeropvollenbroeck:2016}
\citation{hurlimann2015glad,diederich2003authorship,koppel2003exploiting}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Text Classification}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Support Vector Machines}{12}}
\citation{koppel2009computational}
\citation{houvardas2006ngram}
\citation{lai2015recurrent}
\citation{goldberg2016primer}
\citation{bagnall2015author,bagnall2016authorship}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Neural Networks}{13}}
\citation{yin2016abcnn}
\citation{bromley1993signature}
\citation{tiflin2012lstm}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Siamese Neural Networks}{14}}
\newlabel{background:siamese}{{2.1.3}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Image Similarity Tasks}{14}}
\citation{chopra2005learning}
\citation{zhu2017deep}
\citation{baraldi2015deep}
\citation{koch2015siamese}
\citation{naaman2017learning}
\citation{hosseini2015similarity}
\citation{yin2016abcnn}
\citation{neculoiu2016learning}
\citation{mueller2016siamese}
\@writefile{toc}{\contentsline {subsubsection}{Text Similarity Tasks}{16}}
\newlabel{siamese-networks-for-nlp}{{2.1.3}{16}}
\citation{mikolov2012subword}
\citation{sutskever2011generating}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Text Generation}{17}}
\newlabel{background:lm}{{2.2}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Neural Language Modelling}{17}}
\newlabel{neural-networks}{{2.2.1}{17}}
\citation{mikolov2012subword}
\citation{gatt2017survey}
\citation{gatt2017survey}
\citation{ficler2017controlling}
\citation{stamatatos2009survey}
\citation{stamatatos2009survey}
\citation{kestemont2014function}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Authorship Attribution}{19}}
\newlabel{authorship-attribution}{{2.3}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Authorship Identification}{19}}
\newlabel{authorship-identification}{{2.3.1}{19}}
\citation{koppel2009computational}
\citation{kestemont2014function}
\citation{basile2017ngram}
\citation{braud2017writing}
\citation{bagnall2015author}
\citation{luyckx2011scalability}
\citation{luyckx2011scalability}
\citation{luyckx2011scalability}
\citation{akimushkin2017role}
\citation{abbasi2008writeprints}
\citation{klimt2004enron}
\citation{koppel2004authorship}
\citation{koppel2009computational}
\citation{koppel2012fundamental}
\citation{koppel2012fundamental,koppel2012authorship}
\citation{koppel2014determining}
\citation{luyckx2008authorship}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Authorship Verification}{22}}
\newlabel{authorship-verification}{{2.3.2}{22}}
\citation{stolerman2011classify}
\citation{stolerman2015authorship}
\citation{stolerman2015authorship}
\citation{stolerman2015authorship}
\citation{halvani2016authorship}
\citation{halvani2016authorship}
\citation{stamatatos2009survey}
\citation{halvani2017authorship}
\citation{bagnall2015author,bagnall2016authorship}
\citation{bagnall2016authorship}
\citation{bagnall2015author}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Neural Networks for Authorship Attribution}{24}}
\newlabel{background:nn-aid}{{2.3.3}{24}}
\citation{bagnall2015author}
\citation{shrestha2017convolutional}
\citation{ruder2016character}
\citation{bagnall2015author}
\citation{shrestha2017convolutional}
\citation{ruder2016character}
\citation{ng2002discriminative}
\citation{yogatama2017generative}
\citation{ng2002discriminative}
\@writefile{toc}{\contentsline {subsubsection}{Generative and Discriminative models}{25}}
\citation{deng2015deep}
\citation{riemer2017representation}
\citation{zoph2016transfer}
\citation{lalor2017improving}
\citation{yoon2017efficient}
\citation{bagnall2015author}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Transfer Learning}{26}}
\newlabel{background:style}{{2.3.4}{26}}
\newlabel{transfer-learning-and-style-transfer}{{2.3.4}{26}}
\citation{gatt2017survey}
\citation{jhamtani2017shakespearizing}
\citation{jhamtani2017shakespearizing}
\citation{kabbara2016stylistic}
\citation{jhamtani2017shakespearizing}
\citation{queneau1981exercises}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Style}{27}}
\citation{gatys2016image}
\citation{raghu2016expressive}
\citation{myers1962myers}
\citation{stolerman2015authorship}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Related tasks}{28}}
\newlabel{related-tasks}{{2.3.6}{28}}
\citation{basile2017ngram}
\citation{verhoeven2016twisty}
\citation{juola2013overview}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Method}{30}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:meth}{{3}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Unsupervised statistical approaches}{30}}
\newlabel{meth:unsupervised}{{3.1}{30}}
\newlabel{authorship-verification-tasks}{{3.1}{30}}
\newlabel{count-based-statistical-experiments}{{3.1}{31}}
\@writefile{toc}{\contentsline {paragraph}{Count-based statistical experiments}{31}}
\newlabel{correlation-based-statistical-experiments}{{3.1}{32}}
\@writefile{toc}{\contentsline {paragraph}{Correlation based statistical experiments}{32}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Support vector machine approaches}{32}}
\newlabel{method:svm}{{3.2}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Authorship identification tasks}{33}}
\newlabel{method:svm-aid}{{3.2.1}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Authorship verification tasks}{33}}
\newlabel{method:svm-av}{{3.2.2}{33}}
\citation{bagnall2015author}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Neural network approaches}{34}}
\newlabel{method:nn}{{3.3}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Authorship Identification Tasks}{34}}
\newlabel{method:nn-aid}{{3.3.1}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Authorship Verification Tasks}{35}}
\newlabel{method:nn-av}{{3.3.2}{35}}
\citation{potthast2016wrote}
\citation{juola2013overview}
\citation{stamatatos2015overview}
\citation{stamatatos2015overview}
\citation{stein2016overview}
\citation{stein2017overview}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Data}{37}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:data}{{4}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}PAN dataset}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}PAN 2014 dataset}{38}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces An overview of the PAN 2014 dataset. \textit  {Docs. / Prob.} refers to the average number of documents per known author. \textit  {Words / Doc.} is an average of the words per document.}}{38}}
\newlabel{tab:pan14data}{{4.1}{38}}
\citation{houvardas2006ngram}
\citation{lewis2004rcv1}
\citation{houvardas2006ngram}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}PAN 2015 dataset}{39}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces An overview of the PAN 2015 dataset. \textit  {Docs. / Prob.} refers to the average number of documents per known author. \textit  {Words / Doc.} is an average of the words per document.}}{39}}
\newlabel{tab:pan15data}{{4.2}{39}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}C50 dataset}{39}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Yelp dataset}{39}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces An overview of the C50 dataset.}}{40}}
\newlabel{tab:c50data}{{4.3}{40}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Models}{41}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:models}{{5}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Unsupervised Statistical Approaches}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Features and Feature Extraction}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces  An overview of the features we used for our unsupervised models. Each feature is normalized as a ratio either by the number of words in the text or the number of characters as specified by `per word' or `per character' above.}}{42}}
\newlabel{tab:unsupfeatures}{{5.1}{42}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces  An excerpt from the known text (\textit  {Der Tag}) and the unknown text (\textit  {The Admirable Crichton}) by J. M. Barrie.}}{43}}
\newlabel{tab:barrietexts}{{5.2}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces The fifteen supporting features for a pair of texts by J. M. Barrie. The Feature column shows the literal word or feature that was used differently in these two texts compared to the rest of the corpus, while the Known and Unknown columns show the z-score for that feature. Positive score indicate that the author used that feature more often than average, while negative scores indicate that the feature was used less often than average.}}{44}}
\newlabel{tab:barrie}{{5.3}{44}}
\citation{scikit-learn}
\citation{robertson2004understanding}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Support Vector Machine Approaches}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Authorship Identification Tasks}{45}}
\newlabel{svmaid}{{5.2.1}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Authorship Verification Tasks}{46}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Example of pairing same-author and different-author verification examples. All pairs are \textit  {same-author} in the first two arrays (before shift), while half are \textit  {different author} in the second two (after shift).}}{47}}
\newlabel{ver-table}{{5.4}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces  Description of our Authorship Verification datasets. Author Length refers to the total number of characters of text we used to represent one author. Text Length is half of this to account for creating \textit  {known} and \textit  {unknown} texts for each author.}}{47}}
\newlabel{verdata-table}{{5.5}{47}}
\citation{karpathy2015unreasonable}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Neural Network Approaches}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Authorship Identification Tasks}{48}}
\newlabel{models:nn-aid}{{5.3.1}{48}}
\citation{abadi2016tensorflow}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces  An example of partially overlapping sequences for 10 characters (note that for the actual model we used sequences of 100 characters). }}{49}}
\newlabel{seq-table}{{5.6}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Authorship Verification Tasks}{49}}
\newlabel{mod:siamese}{{5.3.2}{49}}
\citation{hadsell2006dimensionality}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces The Euclidean distance between text-pairs for the training set (training on the test set).}}{52}}
\newlabel{fig:euc_train}{{5.1}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces The Euclidean distance between text-pairs for the test set (training on the training set)}}{52}}
\newlabel{fig:euc_test}{{5.2}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces The Siamese learned distance between text-pairs for the training set (training on the test set). }}{52}}
\newlabel{fig:siam_train}{{5.3}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces The Siamese learned distance between text-pairs for the test set (training on the training set) }}{52}}
\newlabel{fig:siam_test}{{5.4}{52}}
\citation{cappellato2014clef}
\citation{khonji2014slightly}
\citation{frery2014identification}
\citation{bagnall2015author}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Results}{53}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Unsupervised Statistical Approaches}{53}}
\newlabel{res:unsupervised}{{6.1}{53}}
\citation{khonji2014slightly}
\citation{frery2014identification}
\citation{bagnall2015author}
\citation{khonji2014slightly}
\citation{frery2014identification}
\citation{bagnall2015author}
\citation{bagnall2015author}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces  The comparative results for our Unsupervised method for the basic and correlation models. We present our highest results using thresholds of 0.75 for both models. Khonji=\citet  {khonji2014slightly}, Frery=\citet  {frery2014identification}, Bagnal=\citet  {bagnall2015author}, tr=train, te=test.}}{54}}
\newlabel{tab:unsupres}{{6.1}{54}}
\citation{houvardas2006ngram}
\citation{houvardas2006ngram}
\newlabel{fig:unsupthresh}{{6.1}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces The effect of the threshold on the different datasets. Generally setting the threshold too low or too high worsens the results.}}{55}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Support Vector Machine Approaches}{55}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Authorship Identification Tasks}{55}}
\newlabel{res:svmaid}{{6.2.1}{55}}
\citation{bagnall2015author}
\citation{khonji2014slightly}
\citation{bagnall2015author}
\citation{khonji2014slightly}
\citation{stamatatos2015overview}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Authorship Verification Tasks}{56}}
\newlabel{res:svmav}{{6.2.2}{56}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces  The comparative results for our Support Vector Machine models. We present accuracy scores alongside our F1 scores in order to be able to compare to previous high scores at PAN. \textit  {B/K} is \citet  {bagnall2015author} for 2015 datasets and \citet  {khonji2014slightly} for 2014 datasets. ``Yelp short'' and ``Yelp long'' refer to the datasets summarized in Table 5.5\hbox {}}}{57}}
\newlabel{tab:svmav}{{6.2}{57}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Neural Network Approaches}{57}}
\citation{bagnall2015author}
\citation{bagnall2015author}
\citation{khonji2014slightly}
\citation{bagnall2015author}
\citation{khonji2014slightly}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Authorship Identification Tasks}{58}}
\newlabel{res:nn-aid}{{6.3.1}{58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Authorship Verification Tasks}{58}}
\newlabel{res:siamese}{{6.3.2}{58}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces  The comparative results for our Siamese method, averaged over 10 runs. We present accuracy scores alongside our F1 scores in order to be able to compare to previous high scores at PAN. \textit  {B/K} is \citet  {bagnall2015author} for 2015 datasets and \citet  {khonji2014slightly} for 2014 datasets. Note that datasets marked with * were used to tune the models and the results should not be taken as indicative of evaluation.}}{59}}
\newlabel{tab:siameseres}{{6.3}{59}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{60}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{ruauthordate}
\bibdata{ref}
\newlabel{chap:con}{{7}{61}}
\bibcite{abadi2016tensorflow}{{1}{2016}{{Abadi {\em  et~al.}}}{{}}}
\bibcite{abbasi2008writeprints}{{2}{2008}{{Abbasi \& Chen}}{{}}}
\bibcite{afroz2014doppelganger}{{3}{2014}{{Afroz {\em  et~al.}}}{{}}}
\bibcite{akimushkin2017role}{{4}{2017}{{Akimushkin {\em  et~al.}}}{{}}}
\bibcite{bagnall2015author}{{5}{2015}{{Bagnall}}{{}}}
\bibcite{bagnall2016authorship}{{6}{2016}{{Bagnall}}{{}}}
\bibcite{baraldi2015deep}{{7}{2015}{{Baraldi {\em  et~al.}}}{{}}}
\bibcite{basile2017ngram}{{8}{2017}{{Basile {\em  et~al.}}}{{}}}
\bibcite{braud2017writing}{{9}{2017}{{Braud \& SÃ¸gaard}}{{}}}
\bibcite{bromley1993signature}{{10}{1993}{{Bromley {\em  et~al.}}}{{}}}
\bibcite{busgeropvollenbroeck:2016}{{11}{2016}{{{Busger op Vollenbroek} {\em  et~al.}}}{{}}}
\bibcite{cappellato2014clef}{{12}{2014}{{Cappellato {\em  et~al.}}}{{}}}
\bibcite{chopra2005learning}{{13}{2005}{{Chopra {\em  et~al.}}}{{}}}
\bibcite{deng2015deep}{{14}{2015}{{Deng \& Jaitly}}{{}}}
\bibcite{diederich2003authorship}{{15}{2003}{{Diederich {\em  et~al.}}}{{}}}
\bibcite{ficler2017controlling}{{16}{2017}{{Ficler \& Goldberg}}{{}}}
\bibcite{frery2014identification}{{17}{2014}{{Fr{\'e}ry {\em  et~al.}}}{{}}}
\citation{cappellato2014clef}
\bibcite{gatt2017survey}{{18}{2017}{{Gatt \& Krahmer}}{{}}}
\bibcite{gatys2016image}{{19}{2016}{{Gatys {\em  et~al.}}}{{}}}
\bibcite{goldberg2016primer}{{20}{2016}{{Goldberg}}{{}}}
\bibcite{hadsell2006dimensionality}{{21}{2006}{{Hadsell {\em  et~al.}}}{{}}}
\bibcite{halvani2016authorship}{{22}{2016}{{Halvani {\em  et~al.}}}{{}}}
\bibcite{halvani2017authorship}{{23}{2017}{{Halvani {\em  et~al.}}}{{}}}
\bibcite{hosseini2015similarity}{{24}{2015}{{Hosseini-Asl \& Guha}}{{}}}
\bibcite{houvardas2006ngram}{{25}{2006}{{Houvardas \& Stamatatos}}{{}}}
\bibcite{hurlimann2015glad}{{26}{2015}{{H{\"u}rlimann {\em  et~al.}}}{{}}}
\bibcite{jhamtani2017shakespearizing}{{27}{2017}{{Jhamtani {\em  et~al.}}}{{}}}
\bibcite{joachims1998text}{{28}{1998}{{Joachims}}{{}}}
\bibcite{juola2013overview}{{29}{2013}{{Juola \& Stamatatos}}{{}}}
\bibcite{kabbara2016stylistic}{{30}{2016}{{Kabbara \& Cheung}}{{}}}
\bibcite{karpathy2015unreasonable}{{31}{2015}{{Karpathy}}{{}}}
\bibcite{kestemont2014function}{{32}{2014}{{Kestemont}}{{}}}
\bibcite{khonji2014slightly}{{33}{2014}{{Khonji \& Iraqi}}{{}}}
\bibcite{klimt2004enron}{{34}{2004}{{Klimt \& Yang}}{{}}}
\bibcite{koch2015siamese}{{35}{2015}{{Koch {\em  et~al.}}}{{}}}
\bibcite{koppel2003exploiting}{{36}{2003}{{Koppel \& Schler}}{{}}}
\bibcite{koppel2004authorship}{{37}{2004}{{Koppel \& Schler}}{{}}}
\bibcite{koppel2014determining}{{38}{2014}{{Koppel \& Winter}}{{}}}
\bibcite{koppel2009computational}{{39}{2009}{{Koppel {\em  et~al.}}}{{}}}
\bibcite{koppel2012authorship}{{40}{2012a}{{Koppel {\em  et~al.}}}{{}}}
\bibcite{koppel2012fundamental}{{41}{2012b}{{Koppel {\em  et~al.}}}{{}}}
\bibcite{Kravalova:2009:CNE:1699705.1699748}{{42}{2009}{{Kravalov\'{a} \& \v {Z}abokrtsk\'{y}}}{{}}}
\bibcite{lai2015recurrent}{{43}{2015}{{Lai {\em  et~al.}}}{{}}}
\bibcite{lalor2017improving}{{44}{2017}{{Lalor {\em  et~al.}}}{{}}}
\bibcite{lewis2004rcv1}{{45}{2004}{{Lewis {\em  et~al.}}}{{}}}
\bibcite{luyckx2011scalability}{{46}{2011}{{Luyckx}}{{}}}
\bibcite{luyckx2008authorship}{{47}{2008}{{Luyckx \& Daelemans}}{{}}}
\bibcite{mikolov2012subword}{{48}{2012}{{Mikolov {\em  et~al.}}}{{}}}
\bibcite{mueller2016siamese}{{49}{2016}{{Mueller \& Thyagarajan}}{{}}}
\bibcite{myers1962myers}{{50}{1962}{{Myers}}{{}}}
\bibcite{naaman2017learning}{{51}{2017}{{Naaman {\em  et~al.}}}{{}}}
\bibcite{neculoiu2016learning}{{52}{2016}{{Neculoiu {\em  et~al.}}}{{}}}
\bibcite{ng2002discriminative}{{53}{2002}{{Ng \& Jordan}}{{}}}
\bibcite{scikit-learn}{{54}{2011}{{Pedregosa {\em  et~al.}}}{{}}}
\bibcite{potthast2016wrote}{{55}{2016}{{Potthast {\em  et~al.}}}{{}}}
\bibcite{queneau1981exercises}{{56}{1981}{{Queneau}}{{}}}
\bibcite{raghu2016expressive}{{57}{2016}{{Raghu {\em  et~al.}}}{{}}}
\bibcite{riemer2017representation}{{58}{2017}{{Riemer {\em  et~al.}}}{{}}}
\bibcite{robertson2004understanding}{{59}{2004}{{Robertson}}{{}}}
\bibcite{ruder2016character}{{60}{2016}{{Ruder {\em  et~al.}}}{{}}}
\bibcite{shrestha2017convolutional}{{61}{2017}{{Shrestha {\em  et~al.}}}{{}}}
\bibcite{stamatatos2009survey}{{62}{2009}{{Stamatatos}}{{}}}
\bibcite{stamatatos2015overview}{{63}{2014}{{Stamatatos {\em  et~al.}}}{{}}}
\bibcite{stein2016overview}{{64}{2016}{{Stamatatos {\em  et~al.}}}{{}}}
\bibcite{stolerman2015authorship}{{65}{2015}{{Stolerman}}{{}}}
\bibcite{stolerman2011classify}{{66}{2011}{{Stolerman {\em  et~al.}}}{{}}}
\bibcite{sutskever2011generating}{{67}{2011}{{Sutskever {\em  et~al.}}}{{}}}
\bibcite{tiflin2012lstm}{{68}{2012}{{Tiflin \& Omlin}}{{}}}
\bibcite{stein2017overview}{{69}{2017}{{Tschuggnall {\em  et~al.}}}{{}}}
\bibcite{verhoeven2016twisty}{{70}{2016}{{Verhoeven {\em  et~al.}}}{{}}}
\bibcite{yin2016abcnn}{{71}{2016}{{Yin {\em  et~al.}}}{{}}}
\bibcite{yogatama2017generative}{{72}{2017}{{Yogatama {\em  et~al.}}}{{}}}
\bibcite{yoon2017efficient}{{73}{2017}{{Yoon {\em  et~al.}}}{{}}}
\bibcite{zhu2017deep}{{74}{2017}{{Zhu {\em  et~al.}}}{{}}}
\bibcite{zoph2016transfer}{{75}{2016}{{Zoph {\em  et~al.}}}{{}}}
